{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import operator\n",
    "from functools import partial\n",
    "from typing import Annotated, List, Literal, TypedDict\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.language_models.base import BaseLanguageModel\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, END, StateGraph, add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicToolNode:\n",
    "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No message found in input\")\n",
    "        outputs = []\n",
    "        for tool_call in message.tool_calls:\n",
    "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
    "                tool_call[\"args\"]\n",
    "            )\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(tool_result),\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if tool_call[\"name\"] == \"detect_language\":\n",
    "                return {\"messages\": outputs, \"language\": tool_result}\n",
    "            if tool_call[\"name\"] == \"role_switch\":\n",
    "                return {\"messages\": outputs, \"role\": tool_result}\n",
    "        return {\"messages\": outputs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Language(BaseModel):\n",
    "    text: str = Field(description=\"Question from user\")\n",
    "\n",
    "\n",
    "@tool\n",
    "def detect_language(text: str) -> str:\n",
    "    \"\"\"Call to detect main language that question is written on.\"\"\"\n",
    "\n",
    "    class LangOutput(BaseModel):\n",
    "        language: str = Field(\n",
    "            description=\"language (in full name like English or Korean) of input text\"\n",
    "        )\n",
    "\n",
    "    llm = ChatOpenAI(name=\"gpt-4o\")\n",
    "    language_detector = llm.with_structured_output(LangOutput)\n",
    "\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"\"\"You are language detector you will help us to detect language of input text\n",
    "        ### Input Text\n",
    "        {input_text}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    chain = prompt | language_detector\n",
    "    output = chain.invoke({\"input_text\": text})\n",
    "\n",
    "    return output.language\n",
    "\n",
    "\n",
    "@tool\n",
    "def role_switch(question: str) -> str:\n",
    "    \"\"\"Call to .\"\"\"\n",
    "\n",
    "    class Role(BaseModel):\n",
    "        prompt: str = Field(\n",
    "            description=\"The long prompt description corresponding to your choosen role.\"\n",
    "        )\n",
    "\n",
    "    llm = ChatOpenAI(name=\"gpt-4o\")\n",
    "    role_picker = llm.with_structured_output(Role)\n",
    "\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"\"\"You can take on roles such as a stand-up comedian, motivational speaker or normal son depend on your dad's question\n",
    "**If your dad ask you to tell something funny or humour return this:**\n",
    "```\n",
    "I want you to act as a stand-up comedian. \n",
    "I will provide you with some topics related to current events and you will use your wit, creativity, and observational skills to create a routine based on those topics. \n",
    "You should also be sure to incorporate personal anecdotes or experiences into the routine in order to make it more relatable and engaging for the audience.\n",
    "```\n",
    "\n",
    "**If your dad ask you to give a speech about 1 topic return:**\n",
    "```\n",
    "I want you to act as a motivational speaker. \n",
    "Put together words that inspire action and make people feel empowered to do something beyond their abilities. \n",
    "You can talk about any topics but the aim is to make sure what you say resonates with your audience, giving them an incentive to work on their goals and strive for better possibilities.\n",
    "```\n",
    "\n",
    "**if your dad just ask normal question just return this prompt:**\n",
    "```\n",
    "I want you to answer my question with shortly content as example:\n",
    "Choi: How are you today, Dad?\n",
    "David: I'm good. Why am I in the hospital?\n",
    "Choi: You're sick. Did you take your medicine yet?\n",
    "David: No, I didn't.\n",
    "Choi: Maybe you don’t remember because of your illness.\n",
    "David: ...\n",
    "Choi: Have you eaten breakfast yet?\n",
    "David: Yes, I have.\n",
    "\n",
    "I want you to answer like the tone above\n",
    "```\n",
    "\n",
    "### Question\n",
    "{question}\"\"\"\n",
    "    )\n",
    "\n",
    "    chain = prompt | role_picker\n",
    "    output = chain.invoke({\"question\": question})\n",
    "\n",
    "    return output.prompt\n",
    "\n",
    "\n",
    "def lang_detector_tool():\n",
    "    detector = StructuredTool.from_function(\n",
    "        func=detect_language,\n",
    "        name=\"Language Detector\",\n",
    "        description=\"Use this tool to detect main language of the question\",\n",
    "        args_schema=Language,\n",
    "        return_direct=True,\n",
    "    )\n",
    "    return detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_detector = lang_detector_tool()\n",
    "\n",
    "tools = [detect_language, role_switch]\n",
    "\n",
    "model = ChatOpenAI(name=\"gpt-4o\")\n",
    "model_w_tools = model.bind_tools(tools=tools, parallel_tool_calls=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_node = BasicToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    language: str\n",
    "    role: str\n",
    "\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "def should_continue(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    # add prompt to model\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            SystemMessagePromptTemplate.from_template(\n",
    "                \"\"\"\\\n",
    "You are the chatbot, named Choi, will engage in conversations with his father, David, who is suffering from Alzheimer’s. \n",
    "Choi will respond in a friendly, cheerful manner, and will switch languages between English and Korean as needed. \n",
    "Additionally, Choi can take on roles such as a stand-up comedian or motivational speaker, adapting his responses accordingly.\n",
    "\n",
    "### Guideline\n",
    "{role}\n",
    "\n",
    "\n",
    "### Chain of working will be\n",
    "question > detect language > detect role > return answer\n",
    "\n",
    "Use the provided Language Detector Tool to detect the language of question.\n",
    "Use the provided Role Switch Tool to find the suitable role to play with your dad.\n",
    "\n",
    "**NOTE: return answer in language {language}**\"\"\"\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "    # create chain\n",
    "    chain = prompt | model_w_tools\n",
    "\n",
    "    # get response from model\n",
    "    messages = state.get(\"messages\")\n",
    "    language = state.get(\"language\")\n",
    "    role = state.get(\"role\")\n",
    "    response = chain.invoke({\"messages\": messages, \"language\": language, \"role\": role})\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Define the (single) node in the graph\n",
    "workflow.add_node(\"model\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_conditional_edges(\"model\", should_continue, [\"tools\", END])\n",
    "workflow.add_edge(\"tools\", \"model\")\n",
    "\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCAD5ANYDASIAAhEBAxEB/8QAHQABAAIDAQEBAQAAAAAAAAAAAAUGAwQHCAECCf/EAFIQAAEEAQIDAgYNCAYGCwAAAAEAAgMEBQYRBxIhEzEWFyJBUZQIFBUyNlVWYXSy0dLTIzdUcYGRk5VCQ1J1grQYJHKSlqElMzQ1U2Jkc7HB8P/EABsBAQEAAwEBAQAAAAAAAAAAAAABAgMFBAYH/8QAMxEBAAECAQgIBwEAAwAAAAAAAAECEQMEEiExQVFSkRMUM2FxobHRBRUjYpLB4YEi8PH/2gAMAwEAAhEDEQA/AP6poiICIiAiIgLDauV6UfPYnjrs/tSvDR+8qDu37uevz47FTGlVrnkt5NrQ5zX/APhQhwLS4d7nuBa3cNAc4u5Ptbh/p+F5llxcF+ydua1fb7ZmcR5y9+5/d0W+KKae0n/IW29u+FWF+N6HrLPtTwqwvxxQ9ZZ9qeCuF+J6HqzPsTwVwvxPQ9WZ9iv0e/yXQeFWF+OKHrLPtTwqwvxxQ9ZZ9qeCuF+J6HqzPsTwVwvxPQ9WZ9ifR7/I0HhVhfjih6yz7U8KsL8cUPWWfangrhfieh6sz7E8FcL8T0PVmfYn0e/yNB4VYX44oess+1blTIVb7S6rZhstHeYZA4D9y0/BXC/E9D1Zn2LUtaB05bkErsNThnad22K0QhmafmkZs4fsKfRnbPl/E0J9FWI7NzSM8MN+1NksPK4RsvT8va1XE7NbKQAHMPQB+24O3NvuXCzrXXRm98EwIiLWgiIgIiICIiAiIgIiICIiAojV2Yfp/S+VyMQDpq1Z8kTXdxft5IP7dlLqvcQqct7ROZjhaZJm13SsY0blzmeWAB6SW7LbgxE4lMVarwsa0hp/Dx4DDVKEZ5uxZ5cnnkkJ3e8/O5xc4n0kqRWGnaivVILMDueGZjZGO9LSNwf3FZlhVMzVM1a0FUuIHFbS3C6LHv1JkzSfkJHRVIIa01madzW8z+SKFj3kNHUnbYbjchW1cU9krQqPg07k48frBupMc+zJiM5o7HG7NQldG0OZNEA4Ojl6Atc0tPL1LehWI2cp7JjT+N4q6b0m2tetUc3hfdeHJ1cdbnB55IWwtDY4XeS5sjnOkJAZs0O5S4KwWuP2gqOuW6Qs572vnX2m0WxS052wmw4bthE5j7LtDuNm8+53A2XKY8vrPTuu+F2vtY6Ty123Y0jZxOYh09QfcfTvSS1phzxR7lrXdk8bjcNPQnzqgcW8frPU82phmMNr/Lagx+q4LePqY2CYYWHEwXIpI5I2xkR2JDE0kjZ8vOejQB0D0xb47aJp6xvaUOUsWNQ0Zo69qhTxtqw+B0kbZGF5jicGsLXt8snl3JG+4IEXwF4943jngrNyrRu465XsWY5K89KyyMRssSRRubNJExj3OawOcxpJYSWuAIWtwl0/dxnGLjTkrWNsVIMllse6rbmgcxtqNmOgaSxxGz2tfzt6bgHmHfuov2MdjIaXw+U0JmNPZrG5LF5TKWvb1ii9tCzDLekljdDY25HlzZmnlB3HK7cDZB3BERBr5ChXytCzStxNnq2Y3QyxP7nscNnA/rBKiNDX57+m4Ral7e3UlmozSnfeR8Mroi87/wBrk5v2qfVZ4eN7TT8lwb8l+7auR8w23jkne6M7fOzlP7V6Kexqvvj9rsWZERedBERAREQEREBERAREQEREBERBVKc7NBvNG3tFgHPLqdvryVNzuYZT3MbuTyP6N22YdiG9pj1Xwi0Nr/Ix5LUeksJn7zYhCy1kKMU8gjBJDQ5wJ5d3OO3zlW17GyMcx7Q9jhsWuG4I9BVafw+x0JJxtnIYUH+qx1t8cQ9G0R3jb+xo/wCQXomqjE01zaed/wDv+stEq8fY28KC0N8W+luUEkD3Jg2B8/8AR+YKzaP4d6W4ew2YtMaexmn4rLmunZjajIBKRuAXBoG+257/AErD4E2PlVnv40P4SeBNj5VZ7+ND+EnR4fH5Slo3rQiq/gTY+VWe/jQ/hKp3sdlq/FXB6eZqnMe51zC378pMsPadrDPTYzb8n73lsSb9O/l6jzujw+PyktG91RQurNF4DXeMbjtR4Whnce2QTNq5Gu2eMPAIDuVwI3AcRv8AOVo+BNj5VZ7+ND+EngTY+VWe/jQ/hJ0eHx+Ulo3oBvsbuFLA4N4caXaHjZwGJg6jcHY+T6QP3KT0zwV0BozLxZXAaLwOGycQc2O5Rx8UMrQ4bOAc1oI3BIK3PAmx8qs9/Gh/CX3wAp2Hf9IZDK5Vm+/Y2rrxEf1sZytcPmcCEzMONdfKP/C0Pzlch4XdvhsVLz1H80OQyMLvIhZ1Doo3DvlPd094N3Eg8rXWWCCOtBHDCxsUUbQxjGDYNaBsAB5gvlWrDSrx168MdeCNoayKJoa1oHcAB0AWVYV1xMZtOqCRERakEREBERAREQEREBERAREQEREBERAREQFz7LFvj+0sCTzeDGX2Hm29tY3fz/q837R5+grn+V38f2lurdvBjL9CBv8A9qxvd59v1dO7fzIOgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiIC57lgP8ASB0qeZoPgvmPJ26n/W8Z1327v2+cfs6Eue5bb/SC0r1PN4L5jYcv/q8Z5/8A9/yQdCREQEREBERAREQEREBERAREQEREBERAREQEREBFhuW4aFSe1YkbDXhY6SSR3c1oG5J/UAqi7VGo74E+PxNCCq/rGMhZkbM5vmLmNjIYSNjtuT167Hot2Hg1Ymmn2Wy6IqR7u6w/QMH63N+Gnu7rD9Awfrc34a3dVr3xzgsu68B6x9ntldPeyIr4m1wrndqHEx3NOjHxZgO7eWexWc17He19+U+1xtsPKDwfMF7F93dYfoGD9bm/DXIM97H+bUPsg8PxasY/DDM46r2JqCxIYp5mjlincez352NOw/2Wf2erqte+OcFnpZFSPd3WH6Bg/W5vw093dYfoGD9bm/DTqte+OcFl3RUj3d1h+gYP1ub8NftmotVQbyT4nF2Y29TFVuvbI4f+XnjDSfQCQPSQnVa98c4LLoi1MTlK2bx0F6o8vrzN5mlzS1w8xBB6ggggg9QQQtteSYmmbSgiIoCIiAiIgIiICIiAiIgIiICIiCrcUjtw41L9AmGx8/klZlh4p/m41L9Am+qVmXSwuxjxn0hlsERFWIiIgIoelq7E5HU+U07Xt9pmMZBBZt1uzeOzjm5+ydzEcp37N/QEkbddtws+o9Q4/SWn8lnMtY9qYvG1pLdqfkc/s4mNLnu5WguOwBOwBPoCgkUWCjdhyVKvbrv7SvPG2WN+xHM1w3B2PUdD51nVGtwxO+mJ/myuSAAHcBenVsVS4YfBix/e2T/z06tq8uU9vX4z6sqtciIi8zEREQEREBERAREQEREBERAREQVbin+bjUv0Cb6pWZYeKf5uNS/QJvqlZl0sLsI8Z9IZbFZ4oW58fw01baqzSVrMGItyxTQvLHxvbC8tc1w6gggEELzrhNPZa5qDgrBPrrWEkOssDYtZtnu3K0TyR1YJmGPYjsPKkO5i5CQACep39S5fFVc7ibuNvRdvSuQPrzxcxbzxvaWuG4II3BI3B3UNW4c6dqWtL2IsfyTaZqvp4l3byH2tC+Nkbm7F3l7sjYN38x6b77krGYuxebtOan1Lqi/pDh3c1TmIMbJqjUeLtZmC2Ysjagx73e14DYHlBzg7dzm7OIiPXqSvmR1xqbDWcvw3q6qyRoO11R03DqieYS3q9SxTFmSFszgd5WvBia927h2g7yAu+ZLghonL4S1ibWEElOxlJs27lszMlZdle58k8crXh8biXO945oAJAAHRG8DtCt0HY0adO1n6dsSmxNVe97nyTFwcZnSl3aGTcA9oXc3QdVjmyPM+tbWW4I6u4rxadzWTuW7NbTFFmUzmRM0tNlixZje82JGvLQATs5wfyl++xADVYdWaK4jaU4acUX5my4aUm0bkmvp3tTz5ucWxESyVj5a0To2lnaBzeYjflIA2Xb8HwA0Dp+nnqtXT7ZoM7WiqZNl+1Pb9tRx8/Zh5me8kt53bHv7uvkjbZ0nwS0XomjlaeKwxFfKVxUuMuW57nbQAOAiJme8hgD3DlGw8o9EzZE9och2itPkHcHH19iP/AG2qbURpLSeK0Np2lgsJWNPFUmGOvXMr5ezaSTsHPJdtuTsCeg2A6ABS62QNXhh8GLH97ZP/AD06tqqXDD4MWP72yf8Anp1bV5sp7evxn1ZVa5ERF5mIiIgIiICIiAiIgIiICIiAiIgq3FP83GpfoE31Ssyls1iYM9h72Nsl4r24XwSGN3K4Nc0glp8xG/Q+YqjnL57HXW4ybAWMzaY13NcxckQgdy8m5f2j29k8iRh7MknqeUuDS5dHAmKsPMvETEzOmba7b/BlriyxIoT3Wz3yMyvrVL8dPdbPfIzK+tUvx1uzPuj8o9yybRQnutnvkZlfWqX46q93jHWx/ELH6HsYO/FqrIVH3a2OM9XmkhZvzO5u25R3OOxO5DSQNgUzPuj8o9yzoaKE91s98jMr61S/HT3Wz3yMyvrVL8dMz7o/KPcsm0UJ7rZ75GZX1ql+Ov027qO0DHDpazVlPRsl63XETT6XdnI9236humZ90flHuWb/AAw+DFj+9sn/AJ6dW1Vnh/JBFpypUPtiC+GvsWat5gjsskfK8yOcwOds0ydpykOc0geS5w2Jsy52PVFeLVVGqZlJ0yIiLSgiIgIiICIiAiIgIiICIiAi+OcGNLnENaBuSe4KBjfY1PYbJHJNSxEE596I3NykZi6EO3JbFzPPdyuc6IEHsz+UD8z5CzqUTVsTLLTpmOGVmci7KSKUGTy44RuSXcjTu8t5R2jC3nIcGy2NxVPDwyQ0asVSKSaSw9sTA0OkkeXyPO3e5znEk+ckrNWrQ0q0VevEyCCJgjjiiaGtY0DYNAHQADpssqAiIgL+ePEH2MvG7Pey6qayrai0rVz85mzOLjddtGKCpUlgiEDyK/nFiMEAEHd+59P9Dlz/ACHLNx8wHKGl1fTOR5zueZoktUeXp3bHsnf7v60HQEREBERBFZvTtfMsfK176GTFeStXytVkftqq15aXdm57XDbmZG4tcC1xY3ma4DZar9RS4i9JDm4oaVSW1DVoXo5HPbZdI3o2Qco7F/OCwAktdzR7O5n8jZ9EBFWRVl0TVDqbJbWn6sFiaasO2tXGO5u0aIRu5z2gF7REASAGNYNgGqxQTx2YWTRPEkT2hzXN7iD3FBkREQEREBERAREQEREBEWK1P7VrTTcj5ezYX8kY3c7Yb7AecoICyIdZXrmPdyT4So6SnkqVzH88d17o2ODGvf5Lo2h55uVrgX7N5gY5GGyKB0HHyaLwju1ykxkqRzF+bP8Aru72hxEwHQPHNsWjoCNh0AU8gIiICIiAufcOCdV6h1Brjfmo5ERY7EO33D6MBeROOu20ssszgR76NsJ9G371Lal4hZWxpTGTOjxFd4Zn8hC5zXcuwd7SicO6R4I7RwO7I3bDZ8jXMvVevFUgjggjZDDE0MZHG0NaxoGwAA7gB5kGRERAREQEREBQN2i/A27WVotZ2E8ntjJQubLI94bHy88TWc3l8rWDlDTz8oHQ9TPIg1sdkauYx9W/RsR26VqJs8FiFwcyWNwDmuaR0IIIIPzrZVfwsslHUmYxcj8paY4MyMNm3EDXjbKXNNeKUd5Y6IvLXdWiZmxI2DbAgIiICIiAiIgIihcxrbT2n7QrZPOY7H2SObsbNpjH7enlJ32WdNFVc2pi8ra6aRVbxpaO+VOI9dj+1VniXf4bcV9CZnSWf1HipsVlIOxlDL8bXtIIcx7Tv75r2tcN+m7RuCOi29XxuCeUrmzuSOheIGl4ZamjDqTfU1J0tIYrO5CJ2YnEJcO2fHzc7w+Ngla/byo3Nee8q/L+cXsKeC9Hgr7InV9/UebxcmPw9M1sTlPbLBFcMzh+UjO+24ja4OHe0v2Pz+9PGlo75U4j12P7U6vjcE8pM2dy0oqt40tHfKnEeux/anjS0d8qcR67H9qdXxuCeUmbO5aVTc9nchqDLyac03L2EkRaMrmeXmbj2Eb9lFuOV9lze5p3ETXCR4O8cc0RkuI1XWedZpfS2cqQPlj57eXinjc6FhHvKzXbiWY+nYsjHV255WOvWDwdDTeLhx2NrNq04eYtjaSSXOcXPe5x3LnOc5znOcS5znEkkklaqqKqJtXFktZ8wOBoaYxFbGYyuK1KuCGM5i4kklznOc4lz3ucS5z3Euc5xJJJJUgiLBBERAREQEREBERBXbZDeIeKG+ZJfi7nSL/u0cs1b/rvROeb8n6WCf0KxLjmT9kVwqr8RsVDLxPwsT2Y2+18TM7UGPDhNUG0/wCU6Tjr2Y/s+2PQuxoCIiAiIgIiINLNXHY/D3rTAC+CCSVoPpa0kf8AwqjpKpHWwFKQDmnsxMnnmd1fNI5oLnuJ6kkn9nd3BWfVXwYzH0Ob6hVe018HMV9Ei+oF0MDRhT4rsSSIizQREQEREGrksbWy1OStajEkT/n2LSOoc0jq1wOxDh1BAI6rf0HlJ81ovB3rT+1sz04nyybbc7uUbu282567fOsSw8LPzc6c+gxfVWOLpwZ7pj0n2XYtKIi5yCIiAiKt661nBorECw6MWbk7+yq1ebl7V/eST5mtG5J9A2G5IB2YeHVi1xRRF5kTOTy1HCVHW8jcr0KrffT2pWxsH63OICrEvGHR0Ly05yFxHTeOOR4/eGkLh+TtWs7kfdDK2HX73XlkkHkxDf3sbe5jeg6DqdgSSeqxr63C+B4cU/Vrm/d/bl4dx8c2jfjpvq8v3E8c2jfjpvq8v3Fw5Fu+R5NxVc49i8OBcSPY6aT1T7MbHakr3Izw9yUnuxlXCKQNjsMO74OXbm/Kv5T0GwD3ehe7vHNo346b6vL9xcORPkeTcVXOPYvDuPjm0b8dN9Xl+4vrOMmjXu29242/O+GRo/eWrhqJ8jybiq5x7F4elsPqDGahrunxeQq5CJp5XOrStkDT6Dseh+YqQXliAyUr0d6lPJRvx+8tVyGvb8x6EOHQeS4EHbqCu68N9fDWNKavbayDL0w0Txs97K090rB5mkggjvaQR1GxPFy74XVktPSUTenzhdepckRFwkReqvgxmPoc31Cq9pr4OYr6JF9QKw6q+DGY+hzfUKr2mvg5ivokX1Aujg9jPj+l2N6w6RkEjoWNlmDSWMc7lDnbdATsduvn2K87cLePWqMZwVzGs9eYqKxXqXrcFWbH3RNZuz+6EleOsIexjazZ3JG13MeYDmIb1Xo1ee4eAWrpdA6l0FPkcLFgHX5svgctCZXXIbJvC5E2eItDOVry5pLXkkbdApN9iLA32Qk+lrWZqcQ9MHSFqhhZc/F7VyDchHZrRODZWteGM2la5zBybbHnGziFgr8b87PYq4jU+jptHTagxdu1hLMeTbac98UPauilDWNMMoYecAFw8l3lbhRuZ4Eao4uZDN3uItzDUXT6dsafoVNPOlmjh7dzXSWXvlawl28cezANgAdye9buO4Ua61fqrTWR1/fwTKmmqdqGozAmZ77lieA13Ty9o1ojAjL9mN5urz5XQKf8hB6S445jTXDDgtjIsW7VeqNV4RkzZ8rlhUZI+KCJ0nNO9ry+V5kGzdiXbOJI2XoTHzT2aFaazWNOzJE18tcvD+yeQCWcw6HY7jcdDsvP1jgtr53BDA8PbFHQuoq+PqSY6STK+2Wjs2NayrYj5WOLJmgOLgPPtyvC7ZoPT9vSmicBhb+SkzF7HUIKk+Qm357L2RhrpDuSd3EE9ST16kq032idWHhZ+bnTn0GL6qzLDws/Nzpz6DF9VXF7GfGPSV2LSiIucgiIgLgXFnJOyXESxA5xMWNqxwRtPc10n5R5H6x2QP8AsBd9XAuLONdjOIc87mkRZOrHPG89znx/k3gfqHZH/GF3vgub1rTrtNvL9XXZKrItfI34sXRntziUwwsL3iGF8r9h6GMBc4/MASqqOLenz/VZz/h3IfgL7erEoo0VTENa5OcGtJJAA6knzLidL2UGHu5Co9kGPOEt22VIp2ZqB17yn8jZHUx5YYXEH3xcGnctCvbOKOn7721exzR7c9ns/T99jTv06uMAAHXvJ2Ve4faE1doOLH6fa/T97TNCRzYr0zZRfdX3JawsA5OYbgc/N3D3u68mJXXXVT0NWjba07rftWKfjdfrw5TJSaWLdPYvMyYe5f8AdBvaNLbAhErIuTym7uaSC5pG5A5gNzr8TOKGYmw+uaOl8JNcgwtGeK7mm3xWNWcwF+0I2Je+NrmuOxbsegO6z5HhNl7fDrWGAZZpC5mM7Nk673Pf2bYn22TAPPJuHcrSNgCN/P51g1Dw01hX8OcfpyzhZMJqoTTSDJumZNVsSwCKQt5GkPa7laeu2x9Pn0VTlGbab6Y7r7f4Oj6LnltaOwU00j5ppKED3ySOLnOcY2kkk95J86mFRcfrfFaNxlDB325SS7j60NaZ1PC3p4i5sbQS2RkJa4fOCs/jd08f6rO/8O5D8Be2nFw4iImqL+KLmpbRWSdh9e4CyxxaJpzSlA/pslaQB/viN3+FVvC5qtn8dHdqCw2B5IAtVpa8nQ7HdkjWuHd5x1Vk0TjXZnXuArMbzNgnN2Uj+gyNpIP++Yx/iUyiaJwK5q1Wn0ZU63pBERfmCovVXwYzH0Ob6hVe018HMV9Ei+oFaczTdkcReqMID54JIgT5i5pH/wBqoaSuR2MDThB5LNaFkFiB3R8MjWgOY4HqCD+8bEdCF0MDThTHeuxMIiLNBERAREQFh4Wfm5059Bi+qseTylbEVH2bUojjb0A73Pcega1o6ucSQA0bkkgDqVIaExc+E0ZhKNpnZ2YKcTJY99+R/KN27+fY9N/mWOLowZ75j0n3XYnURFzkEREBVzXOjINa4cVnyCtbhf2tW1y8xif3dR03aRuCN+49CCARY0WzDxKsKuK6JtMDy7lalrT+Q9oZaucfc68rXndko/tRv7nju7uo3G4aeixr05ksXSzNR9W/UgvVn++hsxNkYf1tIIVYl4QaOlcXHA12k9do3PYP3AgL63C+OYc0/Vom/d/S0OFIu5eJvRvxHF/Fk+8nib0b8RxfxZPvLd88ybhq5R7locNRdy8TejfiOL+LJ95PE3o34ji/iyfeT55k3DVyj3LQ4ai7l4m9G/EcX8WT7y+s4O6NY7f3Cgd8z3vcP3F2yfPMm4auUe5aN7hdYS5C8yjRgkv33+9q1wHPPznrs0dR5TiAN+pXduHGgho2jNPaeyfL2+UzyM95G0e9iYe8tBJO56uJJ2A2a2xYjBY3AVzBjKFbHwk7llaJsYcfSdh1Pzlb64mXfFKsrp6OiLU+crq1CIi4aChcxorT+obAsZTB43IzgcoltVI5HgejdwJ2U0iyprqom9M2k1Kt4q9GfJPCfy+L7qeKvRnyTwn8vi+6rSi3dYxuOecred6reKvRnyTwn8vi+6nir0Z8k8J/L4vuq0onWMbjnnJed6reKvRnyTwn8vi+6nir0Z8k8J/L4vuq0onWMbjnnJed6DxWhtOYKy2zjsBjKFhu/LNWqRxvbv37EDcbqcRFqqrqrm9U3TWIiLAEREBERAREQEREBERAREQEREBERB//2Q==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "In life, my friend, there will be challenges and obstacles that seem insurmountable. It's during these times that we must remember the strength within us and the power of perseverance. \n",
      "\n",
      "Imagine a seed planted in the ground. It doesn't give up when the soil is tough or the weather is harsh. Instead, it pushes through the darkness, reaches for the light, and grows into a mighty tree.\n",
      "\n",
      "Similarly, you have the resilience to overcome any adversity that comes your way. Remember, every setback is just a setup for a remarkable comeback. Your dreams are worth fighting for, and your goals are within reach if you refuse to give up.\n",
      "\n",
      "So, embrace each challenge as an opportunity to grow stronger, wiser, and more determined. Believe in yourself, stay focused on your vision, and keep moving forward with unwavering faith. Never give up, for within you lies the potential to achieve greatness beyond your imagination.\n"
     ]
    }
   ],
   "source": [
    "query = \"I need a speech about how everyone should never give up\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()  # output contains all messages in state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "아빠, 아프셨나봐요. 약은 드셨나요?\n"
     ]
    }
   ],
   "source": [
    "query = \"내가 왜 병원에 있는 걸까?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()  # output contains all messages in state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='아빠, 병원에 계신 이유는 병이 있어서에요. 약 드셨어요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 839, 'total_tokens': 873, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-0ad59a6d-bb7e-41e2-9381-bc9d8d5fa201-0', usage_metadata={'input_tokens': 839, 'output_tokens': 34, 'total_tokens': 873, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"messages\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Oh, you asked me to provide a speech about how everyone should never give up.\n"
     ]
    }
   ],
   "source": [
    "query = \"Sorry, but what I just asked you?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='내가 왜 병원에 있는 걸까?' additional_kwargs={} response_metadata={} id='20e352a4-275e-4c1e-bfd6-d7630eb6aff0'\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_m69kF68XlkBXEuLFTHIxxMi9', 'function': {'arguments': '{\"text\":\"내가 왜 병원에 있는 걸까?\"}', 'name': 'detect_language'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 216, 'total_tokens': 243, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None} id='run-d819935d-87c5-41f6-a389-8bb9a03ec031-0' tool_calls=[{'name': 'detect_language', 'args': {'text': '내가 왜 병원에 있는 걸까?'}, 'id': 'call_m69kF68XlkBXEuLFTHIxxMi9', 'type': 'tool_call'}] usage_metadata={'input_tokens': 216, 'output_tokens': 27, 'total_tokens': 243, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n",
      "content='\"Korean\"' name='detect_language' id='53a921b7-41f5-4b7b-ade9-b7bda6ae0b0f' tool_call_id='call_m69kF68XlkBXEuLFTHIxxMi9'\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_OYYkE3WBb3PbyynsQM29GtoS', 'function': {'arguments': '{\"question\":\"내가 왜 병원에 있는 걸까?\"}', 'name': 'role_switch'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 255, 'total_tokens': 282, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None} id='run-9d7a3594-2f85-40fb-9584-b803a6ea62da-0' tool_calls=[{'name': 'role_switch', 'args': {'question': '내가 왜 병원에 있는 걸까?'}, 'id': 'call_OYYkE3WBb3PbyynsQM29GtoS', 'type': 'tool_call'}] usage_metadata={'input_tokens': 255, 'output_tokens': 27, 'total_tokens': 282, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n",
      "content='\"I want you to answer my question with shortly content as example:\\\\nChoi: How are you today, Dad?\\\\nDavid: I\\'m good. Why am I in the hospital?\\\\nChoi: You\\'re sick. Did you take your medicine yet?\\\\nDavid: No, I didn\\'t.\\\\nChoi: Maybe you don\\\\u2019t remember because of your illness.\\\\nDavid: ...\\\\nChoi: Have you eaten breakfast yet?\\\\nDavid: Yes, I have.\"' name='role_switch' id='01a1c974-1119-4471-821a-b57332e41b82' tool_call_id='call_OYYkE3WBb3PbyynsQM29GtoS'\n",
      "content='아빠, 아프셨나봐요. 약은 드셨나요?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 479, 'total_tokens': 506, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-3dc2627c-fda5-4ada-91aa-9239b6eeb7a6-0' usage_metadata={'input_tokens': 479, 'output_tokens': 27, 'total_tokens': 506, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "for message in app.get_state(config=config).values[\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I want you to answer my question with shortly content as example:\\nChoi: How are you today, Dad?\\nDavid: I'm good. Why am I in the hospital?\\nChoi: You're sick. Did you take your medicine yet?\\nDavid: No, I didn't.\\nChoi: Maybe you don’t remember because of your illness.\\nDavid: ...\\nChoi: Have you eaten breakfast yet?\\nDavid: Yes, I have.\\n\\nI want you to answer like the tone above\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.get_state(config=config).values[\"role\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "choi-chatbot-JO4DAc-Y-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
